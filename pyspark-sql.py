# cevheri
# 2020

# NYC Open Data
# Fire Incident Dispatch Data
# The Fire Incident Dispatch Data file contains data that is generated by the
# Starfire Computer Aided Dispatch System. The data spans from the time
# the incident is created in the system to the time the incident is closed in the system.
# It covers information about the incident as it relates to the assignment
# of resources and the Fire Departmentâ€™s response to the emergency.
# To protect personal identifying information in accordance with the Health Insurance Portability
# and Accountability Act (HIPAA), specific locations of incidents are not included
# and have been aggregated to a higher level of detail.
from pyspark.sql import SparkSession
from pyspark.sql import Row



import sys
import os
os.environ['SPARK_HOME'] = "/home/cevher/app/spark-3.0.1-bin-hadoop2.7"
#os.environ['HADOOP_HOME'] = "/home/cevher/app/spark-3.0.1-bin-hadoop2.7/hadoop"
sys.path.append("/home/cevher/app/spark-3.0.1-bin-hadoop2.7/python")
sys.path.append("/home/cevher/app/spark-3.0.1-bin-hadoop2.7/python/lib")


if __name__ == '__main__':
    spark = SparkSession.builder.appName("sql").getOrCreate()


    def map_comma(line):
        fields = line.split(',')
        return Row(indate=fields[1], incls=str(fields[15]))


    lines = spark.sparkContext.textFile("Fire_Incident_Dispatch_Data.csv")  # all data
    header = lines.first()  # extract header
    data = lines.filter(lambda row: row != header)  # filter out header
    fires = data.map(map_comma)
    print(fires)

    schema = spark.createDataFrame(fires).cache()
    schema.createOrReplaceTempView("fires")

    schema.show(100)

    rows = spark.sql("SELECT incls, indate, count(*) FROM fires group by incls, indate")
    print(rows)

    for row in rows:
        print(row)

    schema.groupBy("incls").count().show()